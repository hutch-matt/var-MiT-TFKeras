{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020, MIT Lincoln Laboratory\n",
    "\n",
    "SPDX-License-Identifier: BSD-2-Clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of working with Tensorflow Keras Models\n",
    "\n",
    "While none made any huge breakthroughs on the Moments in Time state-of-the-art, due to the computational costs of training these models on such a large dataset, we would like to make them available to others studying similar problems where transfer learning might be applicable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Overview\n",
    "\n",
    "Three types of \"off-the'shelf\" models are included in this \"Model Zoo\": 2D CNNs ([C2D](https://en.wikipedia.org/wiki/Convolutional_neural_network#Image_recognition)), 3D CNNs ([C3D](https://arxiv.org/pdf/1412.0767.pdf), [one-stream I3D](https://arxiv.org/abs/1705.07750)), and an [LRCN](https://arxiv.org/pdf/1411.4389.pdf) (CNN+LSTM).\n",
    "\n",
    "C2D models were trained by uniformly randomly sampling frames from the input video.  C3D, I3D, and LRCN models were trained by using 16 dense frames randomly sampled from the input video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naming Convention\n",
    "\n",
    "Each of the models is named in the following way: (backbone_name)-(input_shape)-(output_classes)-(training_history).h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptions\n",
    "\n",
    "The original backbones from which these \"off-the-shelf\" models were created and trained are linked to in the table below.  The following is a brief description of the models:\n",
    "\n",
    "| Model | Name | Input Shape | # Classes | Training History |\n",
    "| :----- | :----- | :----- | :----- | :-----|\n",
    "| C3D-16x224x224x3-339-m.h5 | [C3D](https://github.com/axon-research/c3d-keras) ([source license](https://github.com/axon-research/c3d-keras/blob/master/LICENSE.md)) | (16,224,224,3) | 339 | Moments in Time |\n",
    "| D169-224x224x3-339-im.h5 | [DenseNet169](https://www.tensorflow.org/api_docs/python/tf/keras/applications/DenseNet169) ([source license](https://www.apache.org/licenses/LICENSE-2.0)) | (224,224,3)  | 339  | ImageNet (pretrained weights set) <br/> Moments in Time  |\n",
    "| D201-224x224x3-339-im.h5 | [DenseNet201](https://www.tensorflow.org/api_docs/python/tf/keras/applications/DenseNet201) ([source license](https://www.apache.org/licenses/LICENSE-2.0)) | (224,224,3)  | 339  | ImageNet (pretrained weights set) <br/> Moments in Time|\n",
    "| I3DIv1-16x224x224x3-339-ikm.h5 | [Inflated Inception-v1 3D ConvNet](https://github.com/deepmind/kinetics-i3d) ([source license](https://github.com/deepmind/kinetics-i3d/blob/master/LICENSE)) | (16,224,224,3)   | 339   | ImageNet and Kinetics (pretrained weights sets) <br/> Moments in Time  |\n",
    "| I3DIv1-32x224x224x3-339-ikm.h5 | [Inflated Inception-v1 3D ConvNet](https://github.com/deepmind/kinetics-i3d) ([source license](https://github.com/deepmind/kinetics-i3d/blob/master/LICENSE)) | (32,224,224,3)   | 339   | ImageNet and Kinetics (pretrained weights sets) <br/> Moments in Time  |\n",
    "| IRv2-224x224x3-339-ikm.h5 | [Inception-ResNet-v2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionResNetV2) ([source license](https://www.apache.org/licenses/LICENSE-2.0)) | (224,224,3)  | 339  | ImageNet (pretrained weights set) <br/> Moments in Time   |\n",
    "| IRv2avg-64x224x224x3-339-ikm.h5 | [Inception-ResNet-v2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionResNetV2) ([source license](https://www.apache.org/licenses/LICENSE-2.0)) | (64,224,224,3)  | 339  | ImageNet (pretrained weights set) <br/> Moments in Time   |\n",
    "| Iv3-224x224x3-339-im.h5 | [Inception-v3](https://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3) ([source license](https://www.apache.org/licenses/LICENSE-2.0)) |(224,224,3)   | 339   | ImageNet (pretrained weights set) <br/> Moments in Time  |\n",
    "| LRCN-16x224x224x3-339-m6h5 | [Long-term Recurrent Convolutional Network](https://github.com/harvitronix/five-video-classification-methods/blob/master/models.py) ([source license](https://github.com/harvitronix/five-video-classification-methods/blob/master/LICENSE)) | (16,224,224,3)  | 339  | Moments in Time  |\n",
    "| M-224x224x3-339-im.h5 | [MobileNet](https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNet) ([source license](https://www.apache.org/licenses/LICENSE-2.0)) | (224,224,3)   | 339   | ImageNet (pretrained weights set) <br/> Moments in Time  |\n",
    "| Mv2-224x224x3-339-im.h5 | [MobileNet-v2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2) ([source license](https://www.apache.org/licenses/LICENSE-2.0)) | (224,224,3)  | 339  | ImageNet (pretrained weights set) <br/> Moments in Time  |\n",
    "| R50-224x224x3-339-im.h5  | [ResNet50](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50) ([source license](https://www.apache.org/licenses/LICENSE-2.0)) | (224,224,3)  | 339  |ImageNet (pretrained weights set) <br/> Moments in Time   |\n",
    "| VGG19-224x224x3-339-im.h5 | [VGG19](https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG19) ([source license](https://www.apache.org/licenses/LICENSE-2.0)) | (224,224,3)  | 339  | ImageNet (pretrained weights set) <br/> Moments in Time  |\n",
    "| X-224x224x3-339-im.h5 | [Xception](https://www.tensorflow.org/api_docs/python/tf/keras/applications/Xception) ([source license](https://www.apache.org/licenses/LICENSE-2.0)) |(224,224,3)   |339  | ImageNet (pretrained weights set) <br/> Moments in Time|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With These Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading\n",
    "\n",
    "Note that it may be neccessay to disable HDF5 file locking as done below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable file locking\n",
    "import os\n",
    "os.putenv(\"HDF5_USE_FILE_LOCKING\", \"FALSE\")\n",
    "os.system(\"export $HDF5_USE_FILE_LOCKING\")\n",
    "\n",
    "# Load the model\n",
    "from tensorflow.python.keras.models import load_model\n",
    "model_file = ### TODO: add file path here ###\n",
    "model = load_model(model_file)\n",
    "\n",
    "# View loaded model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing an output layer\n",
    "\n",
    "Once a model has been loaded, it is possible to modify it by accessing its layers feature.  Below is an example of replacing the last layer of model (i.e. the dense classifier) with a new classification layer.  This would be necessary when transfering learning from one dataset to another which have different numbers of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the top layer and replace with a new output layer\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "x = model.layers[-2].output\n",
    "new_output_classes = ### TODO: add number of classes in new dataset here ###\n",
    "x = Dense(new_output_classes, activation=\"softmax\", name='dense_classification')(x)\n",
    "new_model = Model(inputs=old_model.layers[0].input, outputs=x)\n",
    "\n",
    "# View modified model\n",
    "print(new_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging over frames\n",
    "\n",
    "Often, it is useful to average the prediction across multiple frames if using a C2D base.  Here is an example of making this ensemble type model using the model above as a base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = model\n",
    "frames = 64\n",
    "vid_in = Input(shape=(frames,224,224,3), name='video_input')\n",
    "x = TimeDistributed(base_model)(vid_in)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "new_avg_model = Model(inputs=[vid_in],outputs=[x])\n",
    "print(new_avg_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving\n",
    "\n",
    "Once you have modified or trained a model, to save it use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = ### TODO: add output model path here ###\n",
    "model.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "Any questions can be directed to Matthew Hutchinson at <hutchinson@alum.mit.edu>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python license: https://docs.python.org/3/license.html\n",
    "\n",
    "TensorFlow license: https://github.com/tensorflow/tensorflow/blob/master/LICENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
